{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import seaborn as sns; sns.set()\n",
    "import os\n",
    "import dlib\n",
    "from PIL import Image\n",
    "from skimage import exposure\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from IPython.display import clear_output\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "sc = StandardScaler()\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces(image):\n",
    "\n",
    "    # Create a face detector\n",
    "    face_detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "    # Run detector and get bounding boxes of the faces on image.\n",
    "    detected_faces = face_detector(image, 1)\n",
    "    face_frames = [(x.left(), x.top(),\n",
    "                    x.right(), x.bottom()) for x in detected_faces]\n",
    "\n",
    "    return face_frames\n",
    "\n",
    "def contraste(imagen):\n",
    "    clahe = cv2.createCLAHE(clipLimit=3., tileGridSize=(8, 8))\n",
    "    lab = cv2.cvtColor(imagen, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    l2 = clahe.apply(l)\n",
    "    lab = cv2.merge((l2, a, b))\n",
    "    contraste = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "    return contraste\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657/657\n",
      "Data imported!\n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "path_imagen = \"/home/pzampella/NimSet/CropWhiteBackground/\"\n",
    "path_archivo = \"/home/pzampella/NimSet/NimStim_ratings.csv\"\n",
    "data = np.genfromtxt(path_archivo, dtype=None, delimiter=',')\n",
    "\n",
    "# Inputs\n",
    "new_dim = 32\n",
    "classes = 7\n",
    "\n",
    "nombres = []\n",
    "x = []\n",
    "x_flipped = []\n",
    "y = []\n",
    "\n",
    "for i in range(0, len(data)):\n",
    "    clear_output()\n",
    "    print(str(i+1)+\"/\"+str(len(data)))\n",
    "    if os.path.exists(path_imagen + data[i][0].upper()):\n",
    "        nombres.append(data[i][0].upper())\n",
    "        aux0 = cv2.imread(path_imagen + data[i][0].upper(), True)\n",
    "        aux1 = cv2.cvtColor(contraste(aux0), cv2.COLOR_BGR2GRAY)\n",
    "        detected_faces = detect_faces(aux1)\n",
    "        if len(detected_faces) > 0:\n",
    "            face = np.array(Image.fromarray(aux1).crop(detected_faces[0]))\n",
    "            contrast = exposure.equalize_hist(face) * 255\n",
    "            Aux3 = sc.fit_transform(cv2.resize(contrast, (new_dim, new_dim)))\n",
    "            Aux3_flipped = np.flip(Aux3, 1)\n",
    "            aux = np.concatenate(Aux3)\n",
    "            aux_flipped = np.concatenate(Aux3_flipped)\n",
    "            x.append(aux)\n",
    "            x.append(aux_flipped)\n",
    "            y.append(data[i][1])\n",
    "            y.append(data[i][1])\n",
    "\n",
    "y = np.array(y)\n",
    "x =  np.array(x)\n",
    "y = y.reshape(-1,1)\n",
    "ohe = OneHotEncoder()\n",
    "y = ohe.fit_transform(y).toarray()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], new_dim, new_dim, 1))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], new_dim, new_dim, 1))\n",
    "\n",
    "print(\"Data imported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    samplewise_center=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "datagen.fit(x_train, augment=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "10/10 [==============================] - 4s 360ms/step - loss: 1.6849 - acc: 0.3998\n",
      "Epoch 2/200\n",
      "10/10 [==============================] - 2s 208ms/step - loss: 1.3133 - acc: 0.4979\n",
      "Epoch 3/200\n",
      "10/10 [==============================] - 2s 239ms/step - loss: 1.4121 - acc: 0.4059\n",
      "Epoch 4/200\n",
      "10/10 [==============================] - 2s 202ms/step - loss: 1.3345 - acc: 0.4721\n",
      "Epoch 5/200\n",
      "10/10 [==============================] - 2s 172ms/step - loss: 1.1850 - acc: 0.5552\n",
      "Epoch 6/200\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 1.2461 - acc: 0.4836\n",
      "Epoch 7/200\n",
      "10/10 [==============================] - 1s 78ms/step - loss: 1.1412 - acc: 0.5118\n",
      "Epoch 8/200\n",
      "10/10 [==============================] - 1s 65ms/step - loss: 1.3389 - acc: 0.5541\n",
      "Epoch 9/200\n",
      "10/10 [==============================] - 1s 82ms/step - loss: 1.1090 - acc: 0.5529\n",
      "Epoch 10/200\n",
      "10/10 [==============================] - 1s 68ms/step - loss: 0.9066 - acc: 0.6552\n",
      "Epoch 11/200\n",
      "10/10 [==============================] - 1s 68ms/step - loss: 0.9093 - acc: 0.6620\n",
      "Epoch 12/200\n",
      "10/10 [==============================] - 1s 73ms/step - loss: 0.8854 - acc: 0.6070\n",
      "Epoch 13/200\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 0.7691 - acc: 0.6980\n",
      "Epoch 14/200\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.7141 - acc: 0.7475\n",
      "Epoch 15/200\n",
      "10/10 [==============================] - 2s 205ms/step - loss: 0.7272 - acc: 0.7327\n",
      "Epoch 16/200\n",
      "10/10 [==============================] - 1s 76ms/step - loss: 0.8326 - acc: 0.7090\n",
      "Epoch 17/200\n",
      "10/10 [==============================] - 1s 75ms/step - loss: 0.7847 - acc: 0.7329\n",
      "Epoch 18/200\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.8108 - acc: 0.6712\n",
      "Epoch 19/200\n",
      "10/10 [==============================] - 2s 189ms/step - loss: 0.6020 - acc: 0.8009\n",
      "Epoch 20/200\n",
      "10/10 [==============================] - 2s 228ms/step - loss: 0.8200 - acc: 0.7426\n",
      "Epoch 21/200\n",
      "10/10 [==============================] - 2s 222ms/step - loss: 0.6523 - acc: 0.7708\n",
      "Epoch 22/200\n",
      "10/10 [==============================] - 2s 180ms/step - loss: 1.0464 - acc: 0.6351\n",
      "Epoch 23/200\n",
      "10/10 [==============================] - 1s 116ms/step - loss: 0.7042 - acc: 0.7436\n",
      "Epoch 24/200\n",
      "10/10 [==============================] - 2s 150ms/step - loss: 0.6784 - acc: 0.7757\n",
      "Epoch 25/200\n",
      "10/10 [==============================] - 1s 94ms/step - loss: 0.5801 - acc: 0.7902\n",
      "Epoch 26/200\n",
      "10/10 [==============================] - 2s 194ms/step - loss: 0.5670 - acc: 0.8116\n",
      "Epoch 27/200\n",
      "10/10 [==============================] - 3s 274ms/step - loss: 0.5193 - acc: 0.8192\n",
      "Epoch 28/200\n",
      "10/10 [==============================] - 3s 312ms/step - loss: 0.4678 - acc: 0.8495\n",
      "Epoch 29/200\n",
      "10/10 [==============================] - 3s 269ms/step - loss: 0.4659 - acc: 0.8485\n",
      "Epoch 30/200\n",
      "10/10 [==============================] - 3s 346ms/step - loss: 0.7929 - acc: 0.7173\n",
      "Epoch 31/200\n",
      "10/10 [==============================] - 3s 266ms/step - loss: 0.9083 - acc: 0.6853\n",
      "Epoch 32/200\n",
      "10/10 [==============================] - 5s 503ms/step - loss: 0.8204 - acc: 0.7510\n",
      "Epoch 33/200\n",
      "10/10 [==============================] - 4s 408ms/step - loss: 0.6478 - acc: 0.7601\n",
      "Epoch 34/200\n",
      "10/10 [==============================] - 3s 277ms/step - loss: 0.6532 - acc: 0.7990\n",
      "Epoch 35/200\n",
      "10/10 [==============================] - 3s 337ms/step - loss: 0.6122 - acc: 0.7980\n",
      "Epoch 36/200\n",
      "10/10 [==============================] - 3s 339ms/step - loss: 0.4736 - acc: 0.8407\n",
      "Epoch 37/200\n",
      "10/10 [==============================] - 3s 295ms/step - loss: 0.5061 - acc: 0.8242\n",
      "Epoch 38/200\n",
      "10/10 [==============================] - 2s 240ms/step - loss: 0.4477 - acc: 0.8398\n",
      "Epoch 39/200\n",
      "10/10 [==============================] - 3s 269ms/step - loss: 0.6262 - acc: 0.7245\n",
      "Epoch 40/200\n",
      "10/10 [==============================] - 3s 286ms/step - loss: 0.8281 - acc: 0.7096\n",
      "Epoch 41/200\n",
      "10/10 [==============================] - 3s 269ms/step - loss: 0.9625 - acc: 0.6691\n",
      "Epoch 42/200\n",
      "10/10 [==============================] - 2s 204ms/step - loss: 0.5585 - acc: 0.8174\n",
      "Epoch 43/200\n",
      "10/10 [==============================] - 2s 197ms/step - loss: 0.4967 - acc: 0.8145\n",
      "Epoch 44/200\n",
      "10/10 [==============================] - 2s 193ms/step - loss: 0.4633 - acc: 0.8485\n",
      "Epoch 45/200\n",
      "10/10 [==============================] - 2s 189ms/step - loss: 0.5005 - acc: 0.8524\n",
      "Epoch 46/200\n",
      "10/10 [==============================] - 2s 205ms/step - loss: 0.4698 - acc: 0.8427\n",
      "Epoch 47/200\n",
      "10/10 [==============================] - 2s 232ms/step - loss: 0.5000 - acc: 0.8572\n",
      "Epoch 48/200\n",
      "10/10 [==============================] - 2s 200ms/step - loss: 0.4304 - acc: 0.8446\n",
      "Epoch 49/200\n",
      "10/10 [==============================] - 2s 204ms/step - loss: 0.3838 - acc: 0.8689\n",
      "Epoch 50/200\n",
      "10/10 [==============================] - 2s 223ms/step - loss: 0.3175 - acc: 0.8941\n",
      "Epoch 51/200\n",
      "10/10 [==============================] - 2s 246ms/step - loss: 0.3338 - acc: 0.8990\n",
      "Epoch 52/200\n",
      "10/10 [==============================] - 2s 214ms/step - loss: 0.3131 - acc: 0.9194\n",
      "Epoch 53/200\n",
      "10/10 [==============================] - 3s 270ms/step - loss: 0.3277 - acc: 0.9000\n",
      "Epoch 54/200\n",
      "10/10 [==============================] - 2s 215ms/step - loss: 0.2780 - acc: 0.9213\n",
      "Epoch 55/200\n",
      "10/10 [==============================] - 2s 201ms/step - loss: 0.2725 - acc: 0.9233\n",
      "Epoch 56/200\n",
      "10/10 [==============================] - 2s 225ms/step - loss: 0.2500 - acc: 0.9243\n",
      "Epoch 57/200\n",
      "10/10 [==============================] - 2s 204ms/step - loss: 0.3090 - acc: 0.9165\n",
      "Epoch 58/200\n",
      "10/10 [==============================] - 3s 268ms/step - loss: 0.3096 - acc: 0.8922\n",
      "Epoch 59/200\n",
      "10/10 [==============================] - 2s 244ms/step - loss: 0.2751 - acc: 0.9175\n",
      "Epoch 60/200\n",
      "10/10 [==============================] - 2s 219ms/step - loss: 0.3067 - acc: 0.8990\n",
      "Epoch 61/200\n",
      "10/10 [==============================] - 2s 193ms/step - loss: 0.2003 - acc: 0.9499\n",
      "Epoch 62/200\n",
      "10/10 [==============================] - 2s 205ms/step - loss: 0.5799 - acc: 0.8439\n",
      "Epoch 63/200\n",
      "10/10 [==============================] - 2s 215ms/step - loss: 0.6465 - acc: 0.7798\n",
      "Epoch 64/200\n",
      "10/10 [==============================] - 2s 204ms/step - loss: 0.4867 - acc: 0.8582\n",
      "Epoch 65/200\n",
      "10/10 [==============================] - 2s 191ms/step - loss: 0.3145 - acc: 0.8903\n",
      "Epoch 66/200\n",
      "10/10 [==============================] - 2s 190ms/step - loss: 0.2664 - acc: 0.9184\n",
      "Epoch 67/200\n",
      "10/10 [==============================] - 2s 190ms/step - loss: 0.4367 - acc: 0.8699\n",
      "Epoch 68/200\n",
      "10/10 [==============================] - 2s 201ms/step - loss: 0.4084 - acc: 0.8592\n",
      "Epoch 69/200\n",
      "10/10 [==============================] - 2s 204ms/step - loss: 0.3134 - acc: 0.8932\n",
      "Epoch 70/200\n",
      "10/10 [==============================] - 2s 201ms/step - loss: 0.2771 - acc: 0.9213\n",
      "Epoch 71/200\n",
      "10/10 [==============================] - 2s 198ms/step - loss: 0.2892 - acc: 0.9184\n",
      "Epoch 72/200\n",
      "10/10 [==============================] - 2s 210ms/step - loss: 0.2390 - acc: 0.9327\n",
      "Epoch 73/200\n",
      "10/10 [==============================] - 2s 203ms/step - loss: 0.4571 - acc: 0.8485 0s - loss: 0.4570 - acc: 0.851\n",
      "Epoch 74/200\n",
      "10/10 [==============================] - 3s 255ms/step - loss: 0.2971 - acc: 0.8980\n",
      "Epoch 75/200\n",
      "10/10 [==============================] - 2s 222ms/step - loss: 0.4736 - acc: 0.7721\n",
      "Epoch 76/200\n",
      "10/10 [==============================] - 2s 189ms/step - loss: 0.3987 - acc: 0.8022\n",
      "Epoch 77/200\n",
      "10/10 [==============================] - 2s 187ms/step - loss: 0.3339 - acc: 0.8767\n",
      "Epoch 78/200\n",
      "10/10 [==============================] - 2s 197ms/step - loss: 0.2881 - acc: 0.9029\n",
      "Epoch 79/200\n",
      "10/10 [==============================] - 2s 185ms/step - loss: 0.2014 - acc: 0.9381\n",
      "Epoch 80/200\n",
      "10/10 [==============================] - 2s 196ms/step - loss: 0.1836 - acc: 0.9476\n",
      "Epoch 81/200\n",
      "10/10 [==============================] - 2s 211ms/step - loss: 0.2247 - acc: 0.9337\n",
      "Epoch 82/200\n",
      "10/10 [==============================] - 2s 198ms/step - loss: 0.1607 - acc: 0.9592\n",
      "Epoch 83/200\n",
      "10/10 [==============================] - 2s 196ms/step - loss: 0.2753 - acc: 0.9204\n",
      "Epoch 84/200\n",
      "10/10 [==============================] - 2s 184ms/step - loss: 0.2031 - acc: 0.9469\n",
      "Epoch 85/200\n",
      "10/10 [==============================] - 2s 201ms/step - loss: 0.2275 - acc: 0.9272\n",
      "Epoch 86/200\n",
      "10/10 [==============================] - 2s 204ms/step - loss: 0.2185 - acc: 0.9279\n",
      "Epoch 87/200\n",
      "10/10 [==============================] - 2s 178ms/step - loss: 0.1686 - acc: 0.9544\n",
      "Epoch 88/200\n",
      "10/10 [==============================] - 2s 181ms/step - loss: 0.1724 - acc: 0.9505\n",
      "Epoch 89/200\n",
      "10/10 [==============================] - 2s 180ms/step - loss: 0.1539 - acc: 0.9602\n",
      "Epoch 90/200\n",
      "10/10 [==============================] - 2s 209ms/step - loss: 0.1479 - acc: 0.9635\n",
      "Epoch 91/200\n",
      "10/10 [==============================] - 2s 190ms/step - loss: 0.1301 - acc: 0.9660\n",
      "Epoch 92/200\n",
      "10/10 [==============================] - 2s 183ms/step - loss: 0.1007 - acc: 0.9774\n",
      "Epoch 93/200\n",
      "10/10 [==============================] - 2s 187ms/step - loss: 0.1194 - acc: 0.9738\n",
      "Epoch 94/200\n",
      "10/10 [==============================] - 2s 206ms/step - loss: 0.1235 - acc: 0.9702\n",
      "Epoch 95/200\n",
      "10/10 [==============================] - 2s 190ms/step - loss: 0.3825 - acc: 0.8129\n",
      "Epoch 96/200\n",
      "10/10 [==============================] - 2s 193ms/step - loss: 0.2423 - acc: 0.9155\n",
      "Epoch 97/200\n",
      "10/10 [==============================] - 2s 193ms/step - loss: 0.2040 - acc: 0.9281\n",
      "Epoch 98/200\n",
      "10/10 [==============================] - 2s 172ms/step - loss: 0.2374 - acc: 0.9301\n",
      "Epoch 99/200\n",
      "10/10 [==============================] - 2s 183ms/step - loss: 0.1807 - acc: 0.9427\n",
      "Epoch 100/200\n",
      "10/10 [==============================] - 2s 182ms/step - loss: 0.1463 - acc: 0.9660\n",
      "Epoch 101/200\n",
      "10/10 [==============================] - 2s 191ms/step - loss: 0.1460 - acc: 0.9602\n",
      "Epoch 102/200\n",
      "10/10 [==============================] - 2s 212ms/step - loss: 0.1657 - acc: 0.9519\n",
      "Epoch 103/200\n",
      "10/10 [==============================] - 2s 187ms/step - loss: 0.1328 - acc: 0.9636\n",
      "Epoch 104/200\n",
      "10/10 [==============================] - 2s 206ms/step - loss: 0.1246 - acc: 0.9740\n",
      "Epoch 105/200\n",
      "10/10 [==============================] - 2s 192ms/step - loss: 0.0942 - acc: 0.9806\n",
      "Epoch 106/200\n",
      "10/10 [==============================] - 2s 189ms/step - loss: 0.1137 - acc: 0.9738\n",
      "Epoch 107/200\n",
      "10/10 [==============================] - 2s 192ms/step - loss: 0.1559 - acc: 0.9553\n",
      "Epoch 108/200\n",
      "10/10 [==============================] - 2s 191ms/step - loss: 0.1355 - acc: 0.9631\n",
      "Epoch 109/200\n",
      "10/10 [==============================] - 2s 200ms/step - loss: 0.1111 - acc: 0.9699\n",
      "Epoch 110/200\n",
      "10/10 [==============================] - 2s 205ms/step - loss: 0.1025 - acc: 0.9767\n",
      "Epoch 111/200\n",
      "10/10 [==============================] - 2s 196ms/step - loss: 0.0847 - acc: 0.9806\n",
      "Epoch 112/200\n",
      "10/10 [==============================] - 2s 223ms/step - loss: 0.0981 - acc: 0.9815\n",
      "Epoch 113/200\n",
      "10/10 [==============================] - 2s 198ms/step - loss: 0.0814 - acc: 0.9806\n",
      "Epoch 114/200\n",
      "10/10 [==============================] - 2s 221ms/step - loss: 0.0743 - acc: 0.9845\n",
      "Epoch 115/200\n",
      "10/10 [==============================] - 2s 198ms/step - loss: 0.0684 - acc: 0.9893\n",
      "Epoch 116/200\n",
      "10/10 [==============================] - 2s 207ms/step - loss: 0.0587 - acc: 0.9942\n",
      "Epoch 117/200\n",
      "10/10 [==============================] - 2s 223ms/step - loss: 0.0672 - acc: 0.9875\n",
      "Epoch 118/200\n",
      "10/10 [==============================] - 2s 201ms/step - loss: 0.0659 - acc: 0.9883\n",
      "Epoch 119/200\n",
      "10/10 [==============================] - 2s 212ms/step - loss: 0.0553 - acc: 0.9932\n",
      "Epoch 120/200\n",
      "10/10 [==============================] - 3s 257ms/step - loss: 0.0658 - acc: 0.9883\n",
      "Epoch 121/200\n",
      "10/10 [==============================] - 2s 207ms/step - loss: 0.0639 - acc: 0.9922\n",
      "Epoch 122/200\n",
      "10/10 [==============================] - 2s 191ms/step - loss: 0.0618 - acc: 0.9893\n",
      "Epoch 123/200\n",
      "10/10 [==============================] - 3s 317ms/step - loss: 0.0590 - acc: 0.9903\n",
      "Epoch 124/200\n",
      "10/10 [==============================] - 2s 245ms/step - loss: 0.0523 - acc: 0.9933\n",
      "Epoch 125/200\n",
      "10/10 [==============================] - 3s 296ms/step - loss: 0.0491 - acc: 0.9922\n",
      "Epoch 126/200\n",
      "10/10 [==============================] - 3s 265ms/step - loss: 0.0592 - acc: 0.9893\n",
      "Epoch 127/200\n",
      "10/10 [==============================] - 2s 238ms/step - loss: 0.0448 - acc: 0.9961\n",
      "Epoch 128/200\n",
      "10/10 [==============================] - 2s 230ms/step - loss: 0.0581 - acc: 0.9931\n",
      "Epoch 129/200\n",
      "10/10 [==============================] - 2s 204ms/step - loss: 0.0617 - acc: 0.9875\n",
      "Epoch 130/200\n",
      "10/10 [==============================] - 3s 250ms/step - loss: 0.0461 - acc: 0.9961\n",
      "Epoch 131/200\n",
      "10/10 [==============================] - 2s 165ms/step - loss: 0.0493 - acc: 0.9922\n",
      "Epoch 132/200\n",
      "10/10 [==============================] - 3s 269ms/step - loss: 0.0437 - acc: 0.9932\n",
      "Epoch 133/200\n",
      "10/10 [==============================] - 3s 290ms/step - loss: 0.0416 - acc: 0.9922\n",
      "Epoch 134/200\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.0429 - acc: 0.9971\n",
      "Epoch 135/200\n",
      "10/10 [==============================] - 2s 237ms/step - loss: 0.0558 - acc: 0.9951\n",
      "Epoch 136/200\n",
      "10/10 [==============================] - 2s 222ms/step - loss: 0.0868 - acc: 0.9709\n",
      "Epoch 137/200\n",
      "10/10 [==============================] - 2s 203ms/step - loss: 0.0710 - acc: 0.9825\n",
      "Epoch 138/200\n",
      "10/10 [==============================] - 2s 219ms/step - loss: 0.0512 - acc: 0.9933\n",
      "Epoch 139/200\n",
      "10/10 [==============================] - 2s 189ms/step - loss: 0.0390 - acc: 0.9941\n",
      "Epoch 140/200\n",
      "10/10 [==============================] - 2s 222ms/step - loss: 0.0389 - acc: 0.9952\n",
      "Epoch 141/200\n",
      "10/10 [==============================] - 2s 202ms/step - loss: 0.0328 - acc: 0.9971\n",
      "Epoch 142/200\n",
      "10/10 [==============================] - 2s 188ms/step - loss: 0.0375 - acc: 0.9971\n",
      "Epoch 143/200\n",
      "10/10 [==============================] - 2s 217ms/step - loss: 0.0491 - acc: 0.9903\n",
      "Epoch 144/200\n",
      "10/10 [==============================] - 3s 254ms/step - loss: 0.0332 - acc: 0.9951\n",
      "Epoch 145/200\n",
      "10/10 [==============================] - 2s 212ms/step - loss: 0.0373 - acc: 0.9951\n",
      "Epoch 146/200\n",
      "10/10 [==============================] - 3s 302ms/step - loss: 0.0340 - acc: 0.9971\n",
      "Epoch 147/200\n",
      "10/10 [==============================] - 2s 210ms/step - loss: 0.0228 - acc: 0.9990\n",
      "Epoch 148/200\n",
      "10/10 [==============================] - 2s 209ms/step - loss: 0.0284 - acc: 0.9961\n",
      "Epoch 149/200\n",
      "10/10 [==============================] - 2s 221ms/step - loss: 0.0277 - acc: 0.9961\n",
      "Epoch 150/200\n",
      "10/10 [==============================] - 3s 279ms/step - loss: 0.0292 - acc: 0.9971\n",
      "Epoch 151/200\n",
      "10/10 [==============================] - 2s 212ms/step - loss: 0.0283 - acc: 0.9971\n",
      "Epoch 152/200\n",
      "10/10 [==============================] - 3s 308ms/step - loss: 0.0244 - acc: 1.0000\n",
      "Epoch 153/200\n",
      "10/10 [==============================] - 2s 224ms/step - loss: 0.0212 - acc: 0.9990\n",
      "Epoch 154/200\n",
      "10/10 [==============================] - 2s 216ms/step - loss: 0.5149 - acc: 0.9126\n",
      "Epoch 155/200\n",
      "10/10 [==============================] - 2s 228ms/step - loss: 0.3992 - acc: 0.8971\n",
      "Epoch 156/200\n",
      "10/10 [==============================] - 3s 273ms/step - loss: 0.2086 - acc: 0.9587\n",
      "Epoch 157/200\n",
      "10/10 [==============================] - 2s 219ms/step - loss: 0.1205 - acc: 0.9754\n",
      "Epoch 158/200\n",
      "10/10 [==============================] - 2s 236ms/step - loss: 0.1365 - acc: 0.9650\n",
      "Epoch 159/200\n",
      "10/10 [==============================] - 3s 257ms/step - loss: 0.0906 - acc: 0.9760\n",
      "Epoch 160/200\n",
      "10/10 [==============================] - 3s 267ms/step - loss: 0.0667 - acc: 0.9823\n",
      "Epoch 161/200\n",
      "10/10 [==============================] - 3s 278ms/step - loss: 0.0551 - acc: 0.9913\n",
      "Epoch 162/200\n",
      "10/10 [==============================] - 3s 268ms/step - loss: 0.0586 - acc: 0.9893\n",
      "Epoch 163/200\n",
      "10/10 [==============================] - 2s 245ms/step - loss: 0.0441 - acc: 0.9913\n",
      "Epoch 164/200\n",
      "10/10 [==============================] - 3s 257ms/step - loss: 0.0457 - acc: 0.9913\n",
      "Epoch 165/200\n",
      "10/10 [==============================] - 2s 238ms/step - loss: 0.0456 - acc: 0.9922\n",
      "Epoch 166/200\n",
      "10/10 [==============================] - 2s 231ms/step - loss: 0.0457 - acc: 0.9922\n",
      "Epoch 167/200\n",
      "10/10 [==============================] - 3s 250ms/step - loss: 0.0297 - acc: 0.9951\n",
      "Epoch 168/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 3s 257ms/step - loss: 0.0376 - acc: 0.9933\n",
      "Epoch 169/200\n",
      "10/10 [==============================] - 2s 214ms/step - loss: 0.0261 - acc: 1.0000\n",
      "Epoch 170/200\n",
      "10/10 [==============================] - 3s 268ms/step - loss: 0.0382 - acc: 0.9932\n",
      "Epoch 171/200\n",
      "10/10 [==============================] - 2s 211ms/step - loss: 0.0278 - acc: 0.9971\n",
      "Epoch 172/200\n",
      "10/10 [==============================] - 2s 230ms/step - loss: 0.0260 - acc: 0.9990\n",
      "Epoch 173/200\n",
      "10/10 [==============================] - 3s 259ms/step - loss: 0.0281 - acc: 0.9962\n",
      "Epoch 174/200\n",
      "10/10 [==============================] - 2s 205ms/step - loss: 0.0204 - acc: 1.0000\n",
      "Epoch 175/200\n",
      "10/10 [==============================] - 2s 209ms/step - loss: 0.0246 - acc: 0.9961\n",
      "Epoch 176/200\n",
      "10/10 [==============================] - 2s 201ms/step - loss: 0.0288 - acc: 0.9961\n",
      "Epoch 177/200\n",
      "10/10 [==============================] - 2s 197ms/step - loss: 0.0311 - acc: 0.9971\n",
      "Epoch 178/200\n",
      "10/10 [==============================] - 2s 240ms/step - loss: 0.0339 - acc: 0.9942\n",
      "Epoch 179/200\n",
      "10/10 [==============================] - 3s 281ms/step - loss: 0.0301 - acc: 0.9942\n",
      "Epoch 180/200\n",
      "10/10 [==============================] - 2s 206ms/step - loss: 0.0248 - acc: 0.9971\n",
      "Epoch 181/200\n",
      "10/10 [==============================] - 2s 213ms/step - loss: 0.0191 - acc: 1.0000\n",
      "Epoch 182/200\n",
      "10/10 [==============================] - 2s 184ms/step - loss: 0.0191 - acc: 0.9990\n",
      "Epoch 183/200\n",
      "10/10 [==============================] - 2s 205ms/step - loss: 0.0174 - acc: 0.9971\n",
      "Epoch 184/200\n",
      "10/10 [==============================] - 2s 238ms/step - loss: 0.0227 - acc: 0.9981\n",
      "Epoch 185/200\n",
      "10/10 [==============================] - 2s 231ms/step - loss: 0.0723 - acc: 0.9913\n",
      "Epoch 186/200\n",
      "10/10 [==============================] - 4s 359ms/step - loss: 0.2794 - acc: 0.9262\n",
      "Epoch 187/200\n",
      "10/10 [==============================] - 3s 310ms/step - loss: 0.1235 - acc: 0.9612\n",
      "Epoch 188/200\n",
      "10/10 [==============================] - 3s 348ms/step - loss: 0.1028 - acc: 0.9767\n",
      "Epoch 189/200\n",
      "10/10 [==============================] - 4s 396ms/step - loss: 0.0943 - acc: 0.9670\n",
      "Epoch 190/200\n",
      "10/10 [==============================] - 4s 382ms/step - loss: 0.0584 - acc: 0.9835\n",
      "Epoch 191/200\n",
      "10/10 [==============================] - 3s 326ms/step - loss: 0.0388 - acc: 0.9913\n",
      "Epoch 192/200\n",
      "10/10 [==============================] - 3s 349ms/step - loss: 0.0301 - acc: 0.9942\n",
      "Epoch 193/200\n",
      "10/10 [==============================] - 3s 281ms/step - loss: 0.0256 - acc: 0.9951\n",
      "Epoch 194/200\n",
      "10/10 [==============================] - 3s 319ms/step - loss: 0.0281 - acc: 0.9962\n",
      "Epoch 195/200\n",
      "10/10 [==============================] - 2s 214ms/step - loss: 0.0283 - acc: 0.9971\n",
      "Epoch 196/200\n",
      "10/10 [==============================] - 2s 214ms/step - loss: 0.0296 - acc: 0.9913\n",
      "Epoch 197/200\n",
      "10/10 [==============================] - 2s 242ms/step - loss: 0.0400 - acc: 0.9913\n",
      "Epoch 198/200\n",
      "10/10 [==============================] - 2s 233ms/step - loss: 0.0242 - acc: 0.9971\n",
      "Epoch 199/200\n",
      "10/10 [==============================] - 3s 268ms/step - loss: 0.0263 - acc: 0.9961\n",
      "Epoch 200/200\n",
      "10/10 [==============================] - 3s 293ms/step - loss: 0.0232 - acc: 0.9962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1f0ed9dc50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Network Parameters\n",
    "n_input = new_dim*new_dim # data input (img shape: 640*490)\n",
    "n_classes = 7 # total classes (7 emotions: 0=anger, 1=neutral, 2=disgust, 3=fear, 4=happy, 5=sadness, 6=surprise)\n",
    "#np.random.seed(27)\n",
    "classifier= Sequential()\n",
    "\n",
    "classifier.add(Convolution2D(16, (3, 3), activation=\"relu\", input_shape=x_train.shape[1:]))\n",
    "classifier.add(MaxPooling2D(pool_size =(2,2)))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "\n",
    "classifier.add(Dense(units=128, activation=\"relu\"))\n",
    "classifier.add(Dense(units=n_classes, activation=\"sigmoid\"))\n",
    "\n",
    "classifier.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\",\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "#Network training\n",
    "epochs = 200\n",
    "batch = 104\n",
    "\n",
    "#classifier.fit(x_train, y_train, batch_size = batch, epochs = epochs)\n",
    "classifier.fit_generator(datagen.flow(x_train, y_train, batch_size=batch), steps_per_epoch= x_train.shape[0]//batch, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "model_path1 = r'/home/pzampella/NimSet/CNN/Face/Keras/CNN_79_1534936535'\n",
    "json_file = open(model_path1 + r'/model.json', 'r')\n",
    "#Fin cargar archivos\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "classifier = model_from_json(loaded_model_json)\n",
    "classifier.load_weights(model_path1 + r'/model.h5')\n",
    "classifier.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253/261\n",
      "Accuracy: 96%\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(x_test)\n",
    "#y_pred = (y_pred > 0.5)\n",
    "\n",
    "count = 0\n",
    "for i in range(0, y_pred.shape[0]):\n",
    "    if np.argmax(y_pred[i]) == np.argmax(y_test[i]):\n",
    "        count = count+1\n",
    "    else:\n",
    "        continue\n",
    "print(str(count)+\"/\"+str(y_pred.shape[0]))\n",
    "print(\"Accuracy: \"+str(int(100*count/(x_test.shape[0])))+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: 96%\n",
      "B: 97%\n",
      "C: 100%\n",
      "D: 100%\n",
      "E: 97%\n",
      "F: 90%\n",
      "G: 94%\n"
     ]
    }
   ],
   "source": [
    "count0 = 0\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "count3 = 0\n",
    "count4 = 0\n",
    "count5 = 0\n",
    "count6 = 0\n",
    "\n",
    "total0 = 0\n",
    "total1 = 0\n",
    "total2 = 0\n",
    "total3 = 0\n",
    "total4 = 0\n",
    "total5 = 0\n",
    "total6 = 0\n",
    "\n",
    "for i in range(0, y_pred.shape[0]):\n",
    "    if np.argmax(y_pred[i]) == np.argmax(y_test[i]):\n",
    "        if np.argmax(y_test[i]) == 0:\n",
    "            count0 = count0 + 1\n",
    "            total0 = total0 + 1\n",
    "        if np.argmax(y_test[i]) == 1:\n",
    "            count1 = count1 + 1\n",
    "            total1 = total1 + 1\n",
    "        if np.argmax(y_test[i]) == 2:\n",
    "            count2 = count2 + 1\n",
    "            total2 = total2 + 1\n",
    "        if np.argmax(y_test[i]) == 3:\n",
    "            count3 = count3 + 1\n",
    "            total3 = total3 + 1\n",
    "        if np.argmax(y_test[i]) == 4:\n",
    "            count4 = count4 + 1\n",
    "            total4 = total4 + 1\n",
    "        if np.argmax(y_test[i]) == 5:\n",
    "            count5 = count5 + 1\n",
    "            total5 = total5 + 1\n",
    "        if np.argmax(y_test[i]) == 6:\n",
    "            count6 = count6 + 1\n",
    "            total6 = total6 + 1\n",
    "    else:\n",
    "        if np.argmax(y_test[i]) == 0:\n",
    "            total0 = total0 + 1\n",
    "        if np.argmax(y_test[i]) == 1:\n",
    "            total1 = total1 + 1\n",
    "        if np.argmax(y_test[i]) == 2:\n",
    "            total2 = total2 + 1\n",
    "        if np.argmax(y_test[i]) == 3:\n",
    "            total3 = total3 + 1\n",
    "        if np.argmax(y_test[i]) == 4:\n",
    "            total4 = total4 + 1\n",
    "        if np.argmax(y_test[i]) == 5:\n",
    "            total5 = total5 + 1\n",
    "        if np.argmax(y_test[i]) == 6:\n",
    "            total6 = total6 + 1\n",
    "            \n",
    "print(\"A: \" + str(int(100*count0/(total0)))+\"%\")\n",
    "print(\"B: \" + str(int(100*count1/(total1)))+\"%\")\n",
    "print(\"C: \" + str(int(100*count2/(total2)))+\"%\")\n",
    "print(\"D: \" + str(int(100*count3/(total3)))+\"%\")\n",
    "print(\"E: \" + str(int(100*count4/(total4)))+\"%\")\n",
    "print(\"F: \" + str(int(100*count5/(total5)))+\"%\")\n",
    "print(\"G: \" + str(int(100*count6/(total6)))+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to disk\n"
     ]
    }
   ],
   "source": [
    "# save model to JSON\n",
    "folder = '/home/pzampella/NimSet/CNN/Face/Keras/CNN_' + str(int(100*count/(x_test.shape[0]))) + '_' + str(int(time.time())) + '/'\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "model_json = classifier.to_json()\n",
    "with open(folder + 'model.json', \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# save weights to HDF5\n",
    "classifier.save_weights(folder + 'model.h5')\n",
    "print(\"Model saved to disk as\" + folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
